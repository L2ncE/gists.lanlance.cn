## 高并发

### 1. 高并发系统的通用设计方法

高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。

Scale-out（横向拓展）、缓存和异步这三种方法可以在做方案设计时灵活地运用，但它不是具体实施的方案，而是三种思想，在实际运用中会千变万化。

### 2. 高并发下的架构分层

#### 分层有什么好处

- 分层的设计可以简化系统设计，让不同的人专注做某一层次的事情
- 分层之后可以做到很高的复用
- 分层架构可以让我们更容易做横向扩展

#### 如何来做系统分层

- 需要理清楚每个层次的边界是什么
- 层次之间一定是相邻层互相依赖，数据的流转也只能在相邻的两层之间流转

#### 分层架构的不足

- 增加了代码的复杂度
- 把每个层次独立部署，层次间通过网络来交互，那么多层的架构在性能上会有损耗

### 3. 如何提升系统性能

高并发系统设计的三大目标：高性能、高可用、可扩展

#### 性能优化原则

- 性能优化一定不能盲目，一定是问题导向的
- 性能优化也遵循“八二原则”，用 20% 的精力解决 80% 的性能问题。所以我们在优化过程中一定要抓住主要矛盾，优先优化主要的性能瓶颈点
- 性能优化也要有数据支撑。在优化过程中，你要时刻了解你的优化让响应时间减少了多少，提升了多少的吞吐量
- 性能优化的时候要明确目标

#### 性能的度量指标

- 平均值
  平均值对于度量性能来说只能作为一个参考
- 最大值
  过于敏感
- 分位值
  分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感

脱离了并发来谈性能是没有意义的，我们通常使用吞吐量或者同时在线用户数来度量并发和流量，使用吞吐量的情况会更多一些。但是你要知道，这两个指标是呈倒数关系的。

#### 高并发下的性能优化

- 提高系统的处理核心数
  提高系统的处理核心数就是增加系统的并行处理能力
- 减少单次任务响应时间
  CPU 密集型系统中需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段
  IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这类系统的性能瓶颈可能出在系统内部，也可能是依赖的其他系统。可以采用工具和监控的方法进行优化

### 4. 系统怎样做到高可用

#### 可用性的度量

**MTBF（Mean Time Between Failure）**是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。

**MTTR（Mean Time To Repair）**表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。

#### 灰度发布

灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的。一般情况下，灰度发布是以机器维度进行的。比方说，我们先在 10% 的机器上进行变更，同时观察 Dashboard 上的系统性能指标以及错误日志。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。

#### 系统设计思路

- 故障转移
- 超时控制
- 降级
- 限流

### 5. 如何让系统易于拓展

集群系统中，不同的系统分层上可能存在一些“瓶颈点”，这些瓶颈点制约着系统的横线扩展能力。

#### 高可扩展性的设计思路

拆分是提升系统扩展性最重要的一个思路，它会把庞杂的系统拆分成独立的，有单一职责的模块。相对于大系统来说，考虑一个一个小模块的扩展性当然会简单一些。将复杂的问题简单化，这就是我们的思路。

### 6. 如何减少频繁创建数据库连接的性能损耗

使用池化技术

以数据库连接池为例

> 如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；如果连接池中有空闲连接则复用空闲连接；如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（C3P0 的连接池配置是 checkoutTimeout）等待旧的连接可用；如果等待超过了这个设定时间则向用户抛出错误。

- 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。
- 池子中的对象需要在使用之前预先初始化完成，这叫做池子的预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。
- 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。

### 7. 如何实现分库分表

#### 垂直拆分

在微博系统中有和用户相关的表，有和内容相关的表，有和关系相关的表，这些表都存储在主库中。在拆分后，我们期望用户相关的表分拆到用户库中，内容相关的表分拆到内容库中，关系相关的表分拆到关系库中。

#### 水平拆分

- 按照某一个字段的哈希值做拆分，这种拆分规则比较适用于实体表，比如说用户表，内容表，我们一般按照这些实体表的 ID 字段来拆分。比如说我们想把用户表拆分成 16 个库，64 张表，那么可以先对用户 ID 做哈希，哈希的目的是将 ID 尽量打散，然后再对 16 取余，这样就得到了分库后的索引值
- 按照某一个字段的区间来拆分，比较常用的是时间字段。你知道在内容表里面有“创建时间”的字段，而我们也是按照时间来查看一个人发布的内容

### 8. 如何保证分库分表后 ID 的全局唯一性

#### 基于 Snowflake 算法搭建发号器

Snowflake 算法设计的非常简单且巧妙，性能上也足够高效，同时也能够生成具有全局唯一性、单调递增性和有业务含义的 ID，但是它也有一些缺点，其中最大的缺点就是它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止。

### 9. 如何选择缓存的读写策略

1. Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。
2. Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；
3. Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。

### 10. 使用 CDN 进行静态资源加速

#### 如何让用户的请求到达 CDN 节点

CNAME 记录在 DNS 解析过程中可以充当一个中间代理层的角色，可以把将用户最初使用的域名代理到正确的 IP 地址上。

DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间。

#### 如何找到离用户最近的 CDN 节点

GSLB（Global Server Load Balance，全局负载均衡）, 它的含义是对于部署在不同地域的服务器之间做负载均衡，下面可能管理了很多的本地负载均衡组件。它有两方面的作用：

- 它是一种负载均衡服务器，负载均衡，顾名思义嘛，指的是让流量平均分配使得下面管理的服务器的负载更平均；
- 它还需要保证流量流经的服务器与流量源头在地缘上是比较接近的。

GSLB 可以通过多种策略，来保证返回的 CDN 节点和用户尽量保证在同一地缘区域，比如说可以将用户的 IP 地址按照地理位置划分为若干的区域，然后将 CDN 节点对应到一个区域上，然后根据用户所在区域来返回合适的节点；也可以通过发送数据包测量 RTT 的方式来决定返回哪一个节点。

### 11. 每秒 1 万次请求的系统要做服务化拆分吗？

其实，系统的 QPS 并不是决定性的因素。影响的因素可以归纳为以下几点：

- 系统中，使用的资源出现扩展性问题，尤其是数据库的连接数出现瓶颈；
- 大团队共同维护一套代码，带来研发效率的降低，和研发成本的提升；
- 系统部署成本越来越高。

### 12. 微服务化后，系统架构要如何改造？

#### 微服务拆分的原则

- 做到单一服务内部功能的高内聚，和低耦合。
- 你需要关注服务拆分的粒度，先粗略拆分，再逐渐细化。
- 拆分的过程，要尽量避免影响产品的日常功能迭代。

### 13. 通过 RPC 框架实现 10 万 QPS 下毫秒级的服务调用

1. 选择高性能的 I/O 模型，推荐使用同步多路 I/O 复用模型；
2. 调试网络参数，这里面有一些经验值的推荐。比如将 tcp_nodelay 设置为 true，也有一些参数需要在运行中来调试，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小（back log）等等；
3. 序列化协议依据具体业务来选择。如果对性能要求不高，可以选择 JSON，否则可以从 Thrift 和 Protobuf 中选择其一。

### 14. 分布式系统如何寻址？

- 注册中心可以让我们动态地，变更 RPC 服务的节点信息，对于动态扩缩容，故障快速恢复，以及服务的优雅关闭都有重要的意义；
- 心跳机制是一种常见的探测服务状态的方式，在实际的项目中也可以使用；
- 我们需要对注册中心中管理的节点提供一些保护策略，避免节点被过度摘除导致的服务不可用。

### 15. 横跨几十个分布式组件的慢请求要如何排查？

无论是服务追踪还是业务问题排查，你都需要在日志中增加 requestId，这样可以将你的日志串起来，给你呈现一个完整的问题场景。如果 requestId 可以在客户端上生成，在请求业务接口的时候传递给服务端，那么就可以把客户端的日志体系也整合进来，对于问题的排查帮助更大。

采用 traceId + spanId 这两个数据维度来记录服务之间的调用关系（这里 traceId 就是 requestId），也就是使用 traceId 串起单次请求，用 spanId 记录每一次 RPC 调用。

### 16. 怎样提升系统的横向扩展能力？

在微服务架构中，我们也会启动多个服务节点，来承接从用户端到应用服务器的请求，自然会需要一个负载均衡服务器

负载均衡分为两种

- 代理类 —— Nginx
- 客户端类 —— 嵌入 RPC 框架配合服务发现等

### 17. API 网关如何做?

#### 入口网关

- 它提供客户端一个统一的接入地址，API 网关可以将用户的请求动态路由到不同的业务服务上，并且做一些必要的协议转换工作。
- 在 API 网关中，我们可以植入一些服务治理的策略，比如服务的熔断、降级，流量控制和分流。
- 客户端的认证和授权的实现，也可以放在 API 网关中。
- API 网关还可以做一些与黑白名单相关的事情，比如针对设备 ID、用户 IP、用户 ID 等维度的黑白名单。

#### 出口网关

在应用服务器和第三方系统之间，部署出口网关，在出口网关中，对调用外部的 API 做统一的认证、授权，审计以及访问控制。
